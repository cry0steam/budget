{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Setup**\n",
    "##### Download report from BCC\n",
    "1. Go to the web bank client\n",
    "2. Under each currency account choose \"Выписка\"\n",
    "3. After choosing a period -> \"Отправить на почту\" \n",
    "\n",
    "##### Download report from CAIXA\n",
    "1. Go to the web bank client\n",
    "2. Current accounts -> Balances and Operations\n",
    "3. Choose dates and download csv\n",
    "4. Delete header and footer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### to-do\n",
    "- add flag for not using in analysis\n",
    "- check categories per month\n",
    "- add analitics for cashback (and when is is added to the account)\n",
    "- top-10 biggest spendings in every category\n",
    "- check subscriptions\n",
    "- separate preparation of data with analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse bcc euro table\n",
    "df_euro = pd.read_html('euro_bcc_export.html')[2]\n",
    "#parse bcc tenge table\n",
    "df_tenge = pd.read_html('tenge_bcc_export.html')[2]\n",
    "# parse caixa euro table\n",
    "df_euro_caixa = pd.read_csv('euro_caixa_export.csv', sep=\";\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing BCC Euro DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming headers\n",
    "df_euro = df_euro.rename(\n",
    "    columns={\n",
    "        '№ п/п': 'id',\n",
    "        'Дата': 'record_dt',\n",
    "        'Дебет': 'sum',\n",
    "        'Кредит': 'sum_temp',\n",
    "        'Назначение': 'details', }\n",
    ")\n",
    "\n",
    "#changing types\n",
    "df_euro['id'] = df_euro['id'].astype('int')\n",
    "\n",
    "df_euro['sum'] = df_euro['sum'].str.replace(r'\\s+', '', regex=True)\n",
    "df_euro['sum'] = pd.to_numeric(df_euro['sum'])\n",
    "\n",
    "df_euro['sum_temp'] = df_euro['sum_temp'].str.replace(r'\\s+', '', regex=True)\n",
    "df_euro['sum_temp'] = pd.to_numeric(df_euro['sum_temp'])\n",
    "\n",
    "df_euro['record_dt'] = pd.to_datetime(df_euro['record_dt'], format='%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving all sums to one column\n",
    "def move_income_to_sum_column(row):\n",
    "    if pd.isna(row['sum']):\n",
    "        row['sum'] = row['sum_temp']\n",
    "    if pd.isna(row['sum_temp']):\n",
    "        row['sum'] = -row['sum']\n",
    "    return row\n",
    "\n",
    "df_euro = df_euro.apply(move_income_to_sum_column, axis=1)\n",
    "df_euro = df_euro.drop('sum_temp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing details\n",
    "first_word = r'(^\\w+)'\n",
    "forex = r'^Покупка иностранной валюты'\n",
    "atm = r'^Снятие наличных АТМ'\n",
    "transfer = r'^Перевод \\(списание\\)'\n",
    "returns = r'^Прочие зачисления на карту \\(credit\\)'\n",
    "retail_regex = r'^(?:[^,]*,){4}([^,]*)'\n",
    "retail_loc_regex = r'^[^,]*,[^,]*,\\s*([^,]*,[^,]*)'\n",
    "retail_datetime_regex = r'^[^,]*,\\s*(\\d{2}\\.\\d{2}\\.\\d{4} \\d{2}:\\d{2}:\\d{2})'\n",
    "\n",
    "def check_retail(row):\n",
    "    if re.match(first_word, row['details']).group(0) == 'Retail':\n",
    "        row['pos_loc'] = re.search(retail_loc_regex, row['details']).group(1)\n",
    "        row['pos'] = re.search(retail_regex, row['details']).group(1)\n",
    "        row['transaction_dt'] = re.search(retail_datetime_regex, row['details']).group(1)\n",
    "        row['category_1'] = 'retail'\n",
    "    elif re.match(forex, row['details']):\n",
    "        row['category_1'] = 'forex'\n",
    "    elif re.match(atm, row['details']):\n",
    "        row['category_1'] = 'atm'\n",
    "    elif re.match(transfer, row['details']):\n",
    "        row['category_1'] = 'transfer'\n",
    "    elif re.match(returns, row['details']):\n",
    "        row['category_1'] = 'returns'\n",
    "    else:\n",
    "        row['category_1'] = 'unallocated'\n",
    "    return row\n",
    "\n",
    "df_euro = df_euro.apply(check_retail, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expressions to extract date and retail sum directly in the loop\n",
    "cashback_date_regex = r'Дата (\\d{2}\\.\\d{2}\\.\\d{4} \\d{2}:\\d{2}:\\d{2})'\n",
    "retail_sum_regex = r'сумма ([\\d.]+)'\n",
    "\n",
    "# Step 2: Track indices of cashback rows that have matching retail transactions\n",
    "matched_cashback_indices = []\n",
    "\n",
    "# Step 3: Process cashback rows, find matching Retail rows, and add cashback sum\n",
    "for index, row in df_euro.iterrows():\n",
    "    if \"Учет вознаграждений по CashBack\" in row['details']:\n",
    "        # Extract the cashback date and retail transaction sum directly\n",
    "        cashback_date_match = re.search(cashback_date_regex, row['details'])\n",
    "        retail_sum_match = re.search(retail_sum_regex, row['details'])\n",
    "        \n",
    "        if cashback_date_match and retail_sum_match:\n",
    "            cashback_date = cashback_date_match.group(1)\n",
    "            retail_amount = float(retail_sum_match.group(1))\n",
    "            cashback_amount = row['sum']\n",
    "            \n",
    "            # Find matching Retail row by 'transaction_dt' and 'sum'\n",
    "            matching_retail_index = df_euro[(df_euro['transaction_dt'] == cashback_date) & \n",
    "                                            (df_euro['sum'] == -retail_amount)].index\n",
    "            \n",
    "            # If match found, update cashback_sum in the Retail row and mark cashback row for deletion\n",
    "            if not matching_retail_index.empty:\n",
    "                df_euro.loc[matching_retail_index, 'cashback_sum'] = cashback_amount\n",
    "                matched_cashback_indices.append(index)\n",
    "\n",
    "# Step 4: Remove matched cashback rows\n",
    "df_euro.drop(matched_cashback_indices, inplace=True)\n",
    "\n",
    "# Reset index after dropping rows (optional)\n",
    "df_euro.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing BCC Tenge DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#renaming headers\n",
    "df_tenge.columns = [' '.join(col).strip() for col in df_tenge.columns.values]\n",
    "\n",
    "df_tenge = df_tenge.rename(\n",
    "    columns={\n",
    "        df_tenge.columns[0]: 'record_dt',\n",
    "        df_tenge.columns[1]: 'transaction_dt',\n",
    "        df_tenge.columns[2]: 'details',\n",
    "        df_tenge.columns[3]: 'sum_in_currency',\n",
    "        df_tenge.columns[4]: 'currency',\n",
    "        df_tenge.columns[5]: 'fee',\n",
    "        df_tenge.columns[6]: 'sum',\n",
    "        df_tenge.columns[7]: 'cashback',\n",
    "    }\n",
    "    \n",
    ")\n",
    "df_tenge.head(10)\n",
    "\n",
    "df_tenge['sum_in_currency'] = df_tenge['sum_in_currency'].str.replace(r'\\s+', '', regex=True)\n",
    "df_tenge['sum_in_currency'] = pd.to_numeric(df_tenge['sum_in_currency'])\n",
    "\n",
    "df_tenge['sum'] = df_tenge['sum'].str.replace(r'\\s+', '', regex=True)\n",
    "df_tenge['sum'] = pd.to_numeric(df_tenge['sum'])\n",
    "\n",
    "df_tenge['fee'] = df_tenge['fee'].str.replace(r'\\s+', '', regex=True)\n",
    "df_tenge['fee'] = pd.to_numeric(df_tenge['fee'])\n",
    "\n",
    "df_tenge['cashback'] = df_tenge['cashback'].str.replace(r'\\s+', '', regex=True)\n",
    "df_tenge['cashback'] = pd.to_numeric(df_tenge['cashback'])\n",
    "\n",
    "df_tenge['record_dt'] = pd.to_datetime(df_tenge['record_dt'], format='%d.%m.%Y')\n",
    "df_tenge['transaction_dt'] = pd.to_datetime(df_tenge['transaction_dt'], format='%d.%m.%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing details\n",
    "first_word = r'(^\\w+)'\n",
    "forex = r'^Покупка иностранной валюты'\n",
    "cashback = r'^Перевод кешбэка на карту'\n",
    "transfer_to_me1 = r'^Перевод с карты'\n",
    "transfer_to_me2 = r'^Пополнение карт.счета'\n",
    "salary1 = r'^Пополнение от ТОО Яндекс.Казахстан'\n",
    "salary2 = r'^Пополнение от TOO \"Aim High Technology\"'\n",
    "retail_regex = r'^(?:[^,]*,){4}([^,]*)'\n",
    "retail_loc_regex = r'^[^,]*,[^,]*,\\s*([^,]*,[^,]*)'\n",
    "retail_datetime_regex = r'^[^,]*,\\s*(\\d{2}\\.\\d{2}\\.\\d{4} \\d{2}:\\d{2}:\\d{2})'\n",
    "\n",
    "def category_1_parsing(row):\n",
    "    if re.match(first_word, row['details']).group(0) == 'Retail':\n",
    "        row['pos_loc'] = re.search(retail_loc_regex, row['details']).group(1)\n",
    "        row['pos'] = re.search(retail_regex, row['details']).group(1)\n",
    "        row['transaction_dt'] = re.search(retail_datetime_regex, row['details']).group(1)\n",
    "        row['category_1'] = 'retail'\n",
    "    elif re.match(forex, row['details']):\n",
    "        row['category_1'] = 'forex'\n",
    "    elif re.match(transfer_to_me1, row['details']) or re.match(transfer_to_me2, row['details']):\n",
    "        row['category_1'] = 'transfer_to_me'\n",
    "    elif re.match(cashback, row['details']):\n",
    "        row['category_1'] = 'cashback'\n",
    "    elif re.match(salary1, row['details']) or re.match(salary2, row['details']):\n",
    "        row['category_1'] = 'salary'\n",
    "    else:\n",
    "        row['category_1'] = 'unallocated'\n",
    "    return row\n",
    "\n",
    "df_tenge = df_tenge.apply(category_1_parsing, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Caixa Euro DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming headers and changing types\n",
    "df_euro_caixa = df_euro_caixa.rename(\n",
    "    columns={\n",
    "        df_euro_caixa.columns[0]: 'record_dt',\n",
    "        df_euro_caixa.columns[1]: 'transaction_dt',\n",
    "        df_euro_caixa.columns[2]: 'details',\n",
    "        df_euro_caixa.columns[3]: 'sum',\n",
    "        df_euro_caixa.columns[4]: 'sum_temp',\n",
    "    }\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "df_euro_caixa[\"sum_temp\"] = df_euro_caixa[\"sum_temp\"].str.replace(\",\", \"\", regex=False).astype(float)\n",
    "df_euro_caixa['sum_temp'] = pd.to_numeric(df_euro_caixa['sum_temp'])\n",
    "\n",
    "\n",
    "df_euro_caixa[\"sum\"] = df_euro_caixa[\"sum\"].str.replace(\",\", \"\", regex=False).astype(float)\n",
    "df_euro_caixa['sum'] = pd.to_numeric(df_euro_caixa['sum'])\n",
    "\n",
    "df_euro_caixa['record_dt'] = pd.to_datetime(df_euro_caixa['record_dt'], format='%d-%m-%Y')\n",
    "df_euro_caixa['transaction_dt'] = pd.to_datetime(df_euro_caixa['transaction_dt'], format='%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#moving all sums to one column\n",
    "def move_income_to_sum_column(row):\n",
    "    if pd.isna(row['sum']):\n",
    "        row['sum'] = row['sum_temp']\n",
    "    if pd.isna(row['sum_temp']):\n",
    "        row['sum'] = -row['sum']\n",
    "    return row\n",
    "\n",
    "df_euro_caixa = df_euro_caixa.apply(move_income_to_sum_column, axis=1)\n",
    "df_euro_caixa = df_euro_caixa.drop('sum_temp', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing details\n",
    "first_word = r'(^\\w+)'\n",
    "retail = r'^COMPRAS'\n",
    "mbway_transfer = r'^TRF MBWAY'\n",
    "deposit = r'^DEPOSITO'\n",
    "transfer_from_bcc = r'^TRF P2P GERMAN'\n",
    "insurance = r'^Fidelidad'\n",
    "bills_payment = r'^PAGAMENTO'\n",
    "\n",
    "\n",
    "\n",
    "def category_1_parsing(row):\n",
    "    if re.match(retail, row['details']):\n",
    "        row['category_1'] = 'retail'\n",
    "    elif re.match(mbway_transfer, row['details']):\n",
    "        row['category_1'] = 'mbway_transfer'\n",
    "    elif re.match(deposit, row['details']):\n",
    "        row['category_1'] = 'deposit'\n",
    "    elif re.match(transfer_from_bcc, row['details']):\n",
    "        row['category_1'] = 'transfer_from_bcc'\n",
    "    elif re.match(insurance, row['details']):\n",
    "        row['category_1'] = 'insurance'\n",
    "    elif re.match(bills_payment, row['details']):\n",
    "        row['category_1'] = 'bills_payment'\n",
    "    else:\n",
    "        row['category_1'] = 'unallocated'\n",
    "    return row\n",
    "\n",
    "df_euro_caixa = df_euro_caixa.apply(category_1_parsing, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_euro[\"source\"] = \"bcc_euro\"\n",
    "df_tenge[\"source\"] = \"bcc_tenge\"\n",
    "df_euro_caixa[\"source\"] = \"caixa_euro\"\n",
    "\n",
    "df_merged = pd.concat([df_euro, df_tenge, df_euro_caixa], axis=0, join=\"outer\", ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load excel file with category mapping\n",
    "df_cat_mapping = pd.read_excel(\"category_mapping.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "cat_mapping = {}\n",
    "for _, row in df_cat_mapping.iterrows():\n",
    "    cat = row['category']\n",
    "    pos = row['pos']\n",
    "    if cat not in cat_mapping:\n",
    "        cat_mapping[cat] = []\n",
    "    cat_mapping[cat].append(pos)\n",
    "\n",
    "#def assign_category(row):\n",
    " #   for category, keywords in cat_mapping.items():\n",
    "  #      if any(keyword in row['details'] for keyword in keywords):\n",
    "   #         return category\n",
    "    #return 'unallocated'\n",
    "def assign_category(row):\n",
    "    best_category = 'unallocated'\n",
    "    best_keyword_len = 0\n",
    "    \n",
    "    for category, keywords in cat_mapping.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in row[\"details\"]:\n",
    "                if len(keyword) > best_keyword_len:\n",
    "                    best_keyword_len = len(keyword)\n",
    "                    best_category = category\n",
    "                    \n",
    "    return best_category\n",
    "\n",
    "df_merged[\"category_2\"] = df_merged.apply(assign_category, axis=1)\n",
    "df_merged[\"pos\"] = df_merged[\"pos\"].fillna(df_merged[\"details\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged.to_excel(\"report.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_euro[df_euro['category_2'] == 'clothes'].sort_values(by='sum').head(10)\n",
    "\n",
    "monthly_sum = df_merged.groupby([df_merged['record_dt'].dt.to_period('M'), 'category_2'])['sum'].sum().reset_index()\n",
    "\n",
    "# Pivot the DataFrame to have months as columns\n",
    "pivot_table = monthly_sum.pivot(index='category_2', columns='record_dt', values='sum').fillna(0)\n",
    "\n",
    "# Convert the PeriodIndex to a string for clarity\n",
    "pivot_table.columns = pivot_table.columns.astype(str)\n",
    "\n",
    "# Display the pivot table\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a file with uncallocated to manually add to mapping\n",
    "df_cat1_unallocated = df_merged[df_merged[\"category_1\"] == \"unallocated\"]\n",
    "df_cat1_unallocated = df_cat1_unallocated[[\"record_dt\", \"transaction_dt\", \"details\", \"sum\", 'pos']]\n",
    "\n",
    "df_cat2_unallocated = df_merged[df_merged[\"category_2\"] == \"unallocated\"]\n",
    "df_cat2_unallocated = df_cat2_unallocated[[\"record_dt\", \"transaction_dt\",'category_1', \"details\", \"sum\",'pos']]\n",
    "\n",
    "\n",
    "#df_unallocated.to_excel(\"unallocated.xlsx\", index=False)\n",
    "with pd.ExcelWriter(\"unallocated.xlsx\") as writer:\n",
    "    df_cat1_unallocated.to_excel(writer, sheet_name=\"Sheet1\", index=False)\n",
    "    df_cat2_unallocated.to_excel(writer, sheet_name=\"Sheet2\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
